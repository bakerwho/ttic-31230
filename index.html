 <title>TTIC 31230: Fundamentals of Deep Learning</title>

<header>TTIC 31230: Fundamentals of Deep Learning</header>

<p> David McAllester</p>

<p> Winter 2020</p>

<p> TA: Adam Dziedzic</p>
<p> Grader: Gray Mackall </p>

<p style = "color:red"> Announcement: The office hours have been moved to Monday, Friday 2:00-4:00 in the library rm 435.<p>

<p> In 2020, as in 2019, there will be no machine problems or class projects.  The course will again be treated as an "algorithms class" rather than a "programming class".</p>

<p> The grade will be based entirely on four in-class quizes and a final exam with the final worth 30% and each quiz worth 17.5%. The quizes from laset year, with solutions, are given at the bottom of this page.  Also the course material includes additional paractice problems with solutions.  The quizes and the final will include problems from the practice set --- you just need to memorize the solution --- as well as original problems.</p>

<p>Lectures Slides and Course Material:</p>

<ol>

  <li><a href = 01intro/intro.html> Information Theory: The Fundamental Equations of Deep Learning</a></li>

  <li><a href = 02MLP/Backprop.html> Back-Propagation and Frameworks</li>

  <li><a href = 03CNNs/CNNs.html> Convolutional Neural Networks (CNNs)</li>

  <!-- <li><a href = 04Highway/highway.html> Trainability: Initialization, Batch Normalization, ResNet and Gated RNNs </li> -->

  <li><a href = 05RNNs/LangModel.html> Language Modeling, Recurrent Neural Networks (RNNs), Machine Translation and Attention</li>

  <li><a href = 06SGD/SGD.html> Variants of Stochastic Gradient Descent (SGD)</li>

  <li><a href = 07regularization/regularization.html> Generalization and Regularization</li>

  <li><a href = 09GraphicalModels/CTC.html> Connectionist Temporal Classification (CTC)</li>

  <li><a href = 09GraphicalModels/DGMs.html> Deep Graphical Models</li>

  <li><a href = 11AutoEncoders/info.html> More Information Theory: Avoiding Differential Entropy </li>
  
  <li><a href = 11AutoEncoders/Rate.html> Rate-Distortion Autoencoders (RDAs)</li>

  <li><a href = 11AutoEncoders/Variational.html> Expectation Maximization (EM), The Evidence Lower Bound (The ELBO) and Variational Autoencoders (VAEs)</li>

  <li><a href = 14GANs/GANs.html> Generative Adversarial Networks (GANs)</a></li>

  <li><a href = pretraining/pretraining.html> Pretraining</a></li>

  <li><a href = 15RL/RL.html> Reinforcement Learning (RL)</a></li>

  <li><a href = 16alpha/alpha.html> AlphaZero</a></li>

  <li><a href = 13SGD2/SGD2.html> Gradients as Dual Vectors, Hessian-Vector Products, and Information Geometry </a></li>

  <li><a href = 17Interpretation/Interp.html> The Black Box Problem</a></li>

  <li><a href = 18AGI/AGI.html> The Quest for Artificial General Intelligence (AGI)</a></li>
  
</ol>

<p> 2019 Exam problems have been moved to the problems for the appropriate lecture.</p>

<ol>
  <li><a href = quiz1-20/quiz1-20.pdf> Quiz 1, 2020</a></li>
  <li><a href = quiz2-20/quiz2.pdf> Quiz 2, 2020</a></li>
</ol>

<p> Exam Schedule:</p>

<p> Each quiz will occupy the last 2/3 of one class.  The quizes are scheduled two weeks apart as follows: </p>

<ul>
  <li> Quiz 1, Tuesday January 14 covers lectures 1 and 2. </li>
  <li> Quiz 2, Tuesday January 28 covers lectures 3,4, and 5.</li>
  <li> Quiz 3, Tuesday February 11 </li>
  <li> Quiz 4, Tuesday February 25 </li>
</ul>

<p> The final exam is Thursday March 19, 1:30 - 3:30</p>

<p> Office hours will be Monday and Friday 2:00 to 4:00 in the library (TTIC 435).</p>

  


  


